{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a40a0f81-4ddc-4e7a-9ad8-5a8cfada9c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\torye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\torye\\anaconda3\\envs\\GPU\\lib\\site-packages\\IPython\\core\\magics\\osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n",
      "C:\\Users\\torye\\anaconda3\\envs\\GPU\\lib\\site-packages\\IPython\\core\\magics\\osm.py:428: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abee0bae-ed0d-4e0f-b058-ce8fc9257f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from tensorflow.keras import layers, models, Input\n",
    "\n",
    "#tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c25fd4-28f3-40a9-a4c5-561814f639d5",
   "metadata": {},
   "source": [
    "# Attack Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34ed04f8-f6e8-4249-88f8-cc2fe4c7125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('./work/dataset/gear_dataset_hex.csv')\n",
    "#df = pd.read_csv('./work/dataset/RPM_dataset_hex.csv')\n",
    "#df = pd.read_csv('./work/dataset/DoS_dataset_hex.csv')\n",
    "#df = pd.read_csv('./work/dataset/Fuzzy_dataset_hex.csv')\n",
    "\n",
    "\n",
    "#df = pd.read_csv('./work/Survival_and_Challenge_2019/HYUNDAI_Sonata/HY_Sonata_Replay_HEX.csv')\n",
    "\n",
    "\n",
    "df = pd.read_csv('./work/Survival_and_Challenge_2019/KIA_Soul/KIA_Soul_Replay_HEX.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#df = df.iloc[:1000]\n",
    "\n",
    "protocol = \"CAN\"\n",
    "#protocol = \"CAN-FD\"\n",
    "\n",
    "#attack = \"gear\"\n",
    "#attack = \"RPM\"\n",
    "#attack = \"DoS\"\n",
    "#attack = \"Fuzzy\"\n",
    "attack = \"Replay\"\n",
    "\n",
    "#attack = \"Malfunction\"\n",
    "#attack = \"Flooding\"\n",
    "#attack = \"Fuzzing\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a3538c-4895-4545-9663-2b3ae1011927",
   "metadata": {},
   "source": [
    "# Make folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8788bb7-2c24-4cef-b3c7-af5e805eebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#version = \"HY_SONATA\"\n",
    "version = \"KIA_SOUL\"\n",
    "#version = \"CHEVROLET_SPARK\"\n",
    "#version = \"HY_G80\"\n",
    "\n",
    "folder_name = f\"DCNN_Sliding_{protocol}_{version}\"\n",
    "\n",
    "directory = \"./Models/22.DCNN_(VC)\"  # Replace with your desired path\n",
    "path = os.path.join(directory, folder_name)\n",
    "\n",
    "\"\"\"\n",
    "# Check that the folder already exists and Delete folder if it exists\n",
    "if os.path.exists(path):\n",
    "    shutil.rmtree(path) \n",
    "\n",
    "# Create a new folder\n",
    "os.makedirs(path)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6e0612-5d08-493b-9919-97c1269eabff",
   "metadata": {},
   "source": [
    "# Preprocessing : ID Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "545d57d1-aa0f-4535-9a0e-ab9e06388233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "(566310, 29, 29, 1)\n"
     ]
    }
   ],
   "source": [
    "#======================================# \n",
    "print(\"Start\")\n",
    "#======================================# \n",
    "\n",
    "F = 28\n",
    "df = df.drop(['Timestamp'], axis=1)\n",
    "df['Arbitration_ID_binary'] = df['Arbitration_ID'].apply(lambda x: bin(int(x, 16))[2:].zfill(29))\n",
    "np_id = [np.array([int(char) for char in bin_str]) for bin_str in df['Arbitration_ID_binary'].astype(str)]\n",
    "\n",
    "\n",
    "ID_Sequence = []\n",
    "\n",
    "for i in range(df.shape[0] - F):\n",
    "    concatenated_rows = np.concatenate([np_id[i + j] for j in range(F + 1)], axis=0)\n",
    "    ID_Sequence.append(concatenated_rows)\n",
    "\n",
    "\n",
    "# For training_ID\n",
    "training_id = np.array(ID_Sequence)\n",
    "reshaped_array = training_id.reshape(-1, 29, 29, 1)\n",
    "\n",
    "\n",
    "\n",
    "print(reshaped_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958f2d2e-6683-4d14-8d0b-23105e514102",
   "metadata": {},
   "source": [
    "# Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7107b08c-30fc-429e-bbb9-fbf20d2be967",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling = df['Class']\n",
    "labeling = labeling.shift(-F)\n",
    "labeling = labeling.drop(range(labeling.shape[0] - F, labeling.shape[0])).astype(int)\n",
    "labeling = np.array(labeling)\n",
    "\n",
    "\n",
    "num_classes = 2\n",
    "one_hot_labels = to_categorical(labeling, num_classes=num_classes)\n",
    "one_hot_labels_int = one_hot_labels.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8cf95-b660-4ef2-9471-362cd58c377f",
   "metadata": {},
   "source": [
    "# Dataset Split (7:3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7b3aa52-e9bc-4600-93c2-f073594f7519",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reshaped_array, one_hot_labels_int, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670f4dfb-4707-4a25-9e41-c2c83da1f12d",
   "metadata": {},
   "source": [
    "# DCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b1d4d43-0a31-40d2-92ee-b6b01c8046d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Inception_v4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 29, 29, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 29, 29, 32)   320         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 29, 29, 32)  128         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 29, 29, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 27, 27, 32)   9248        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 27, 27, 32)  128         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 27, 27, 32)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 13, 13, 32)   0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 13, 13, 64)   2112        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 13, 13, 64)  256         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 13, 13, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 13, 13, 128)  73856       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 13, 13, 128)  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 13, 13, 128)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 13, 13, 128)  147584      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 13, 13, 128)  512        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 13, 13, 128)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 13, 13, 32)   4128        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 13, 13, 32)  128         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 13, 13, 32)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 13, 13, 32)   4128        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 13, 13, 32)   9248        ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 13, 13, 32)  128         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 13, 13, 32)  128         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 13, 13, 32)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 13, 13, 32)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 13, 13, 32)   4128        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 13, 13, 32)   9248        ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 13, 13, 32)   9248        ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 13, 13, 32)  128         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 13, 13, 32)  128         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 13, 13, 32)  128         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 13, 13, 32)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 13, 13, 32)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 13, 13, 32)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 13, 13, 96)   0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 13, 13, 128)  12416       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " Inception_ResNet_Block_A0 (Add  (None, 13, 13, 128)  0          ['activation_4[0][0]',           \n",
      " )                                                                'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 13, 13, 128)  512        ['Inception_ResNet_Block_A0[0][0]\n",
      " ormalization)                                                   ']                               \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 13, 13, 128)  0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 13, 13, 96)   12384       ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 13, 13, 96)  384         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 13, 13, 96)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 13, 13, 96)   83040       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 13, 13, 96)  384         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 13, 13, 96)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 6, 6, 192)    221376      ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 6, 6, 128)    110720      ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 6, 6, 192)   768         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 6, 6, 128)   512         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 6, 6, 128)   0           ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 6, 6, 192)    0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 6, 6, 128)    0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " Reduction_Block_A (Concatenate  (None, 6, 6, 448)   0           ['max_pooling2d_1[0][0]',        \n",
      " )                                                                'activation_12[0][0]',          \n",
      "                                                                  'activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 6, 6, 448)   1792        ['Reduction_Block_A[0][0]']      \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 6, 6, 448)    0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 6, 6, 64)     28736       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 6, 6, 64)    256         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 6, 6, 64)     0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 6, 6, 64)     12352       ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 6, 6, 64)    256         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 6, 6, 64)     0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 6, 6, 64)     28736       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 6, 6, 64)     12352       ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 6, 6, 64)    256         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 6, 6, 64)    256         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 6, 6, 64)     0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 6, 6, 64)     0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 6, 6, 128)    0           ['activation_17[0][0]',          \n",
      "                                                                  'activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 6, 6, 448)    57792       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " Inception_ResNet_Block_B0 (Add  (None, 6, 6, 448)   0           ['activation_16[0][0]',          \n",
      " )                                                                'conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 6, 6, 448)   1792        ['Inception_ResNet_Block_B0[0][0]\n",
      " ormalization)                                                   ']                               \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 6, 6, 448)    0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 6, 6, 128)    57472       ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 6, 6, 128)   512         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 6, 6, 128)    0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 6, 6, 128)    57472       ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 6, 6, 128)    57472       ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 6, 6, 128)    147584      ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 6, 6, 128)   512         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 6, 6, 128)   512         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 6, 6, 128)   512         ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 6, 6, 128)    0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 6, 6, 128)    0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 6, 6, 128)    0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 2, 2, 192)    221376      ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 2, 2, 128)    147584      ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 2, 2, 128)    147584      ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 2, 2, 192)   768         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 2, 2, 128)   512         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 2, 2, 128)   512         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 2, 2, 448)   0           ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 2, 2, 192)    0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 2, 2, 128)    0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 2, 2, 128)    0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 2, 2, 896)    0           ['max_pooling2d_2[0][0]',        \n",
      "                                                                  'activation_23[0][0]',          \n",
      "                                                                  'activation_25[0][0]',          \n",
      "                                                                  'activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 2, 2, 896)   3584        ['concatenate_2[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 2, 2, 896)    0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 896)         0           ['activation_29[0][0]']          \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 896)          0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 896)          0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2)            1794        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,708,386\n",
      "Trainable params: 1,699,938\n",
      "Non-trainable params: 8,448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#======================================#  \n",
    "#   Reduced_Inception_ResNet\n",
    "#======================================#  \n",
    "\n",
    "def Conv_2D_Block(x, model_width, kernel, strides=(1, 1), padding=\"same\"):\n",
    "    # 2D Convolutional Block with BatchNormalization\n",
    "    x = tf.keras.layers.Conv2D(model_width, kernel, strides=strides, padding=padding, kernel_initializer=\"he_normal\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def classifier(inputs, class_number):\n",
    "    # Construct the Classifier Group\n",
    "    # inputs       : input vector\n",
    "    # class_number : number of output classes\n",
    "    out = tf.keras.layers.Dense(class_number, activation='softmax')(inputs)\n",
    "    return out\n",
    "\n",
    "\n",
    "def regressor(inputs, feature_number):\n",
    "    # Construct the Regressor Group\n",
    "    # inputs         : input vector\n",
    "    # feature_number : number of output features\n",
    "    out = tf.keras.layers.Dense(feature_number, activation='linear')(inputs)\n",
    "    return out\n",
    "\n",
    "\n",
    "def Inception_ResNet_Module_A(inputs, filterB1_1, filterB2_1, filterB2_2, filterB3_1, filterB3_2, filterB3_3, filterB4_1, i):\n",
    "    # Inception ResNet Module A - Block i\n",
    "    branch1x1 = Conv_2D_Block(inputs, filterB1_1, (1, 1))\n",
    "\n",
    "    branch3x3 = Conv_2D_Block(inputs, filterB2_1, (1, 1))\n",
    "    branch3x3 = Conv_2D_Block(branch3x3, filterB2_2, (3, 3))\n",
    "\n",
    "    branch3x3dbl = Conv_2D_Block(inputs, filterB3_1, (1, 1))\n",
    "    branch3x3dbl = Conv_2D_Block(branch3x3dbl, filterB3_2, (3, 3))\n",
    "    branch3x3dbl = Conv_2D_Block(branch3x3dbl, filterB3_3, (3, 3))\n",
    "\n",
    "    branch_concat = tf.keras.layers.concatenate([branch1x1, branch3x3, branch3x3dbl], axis=-1)\n",
    "    branch1x1_ln = tf.keras.layers.Conv2D(filterB4_1, (1, 1), activation='linear', strides=(1, 1), padding='same', kernel_initializer=\"he_normal\")(branch_concat)\n",
    "\n",
    "    x = tf.keras.layers.Add(name='Inception_ResNet_Block_A'+str(i))([inputs, branch1x1_ln])\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    out = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def Inception_ResNet_Module_B(inputs, filterB1_1, filterB2_1, filterB2_2, filterB2_3, filterB3_1, i):\n",
    "    # Inception ResNet Module B - Block i\n",
    "    branch1x1 = Conv_2D_Block(inputs, filterB1_1, (1, 1))\n",
    "\n",
    "    branch7x7 = Conv_2D_Block(inputs, filterB2_1, (1, 1))\n",
    "    branch7x7 = Conv_2D_Block(branch7x7, filterB2_2, (1, 3))\n",
    "    branch7x7 = Conv_2D_Block(branch7x7, filterB2_3, (3, 1))\n",
    "\n",
    "    branch_concat = tf.keras.layers.concatenate([branch1x1, branch7x7], axis=-1)\n",
    "    branch1x1_ln = tf.keras.layers.Conv2D(filterB3_1, (1, 1), activation='linear', strides=(1, 1), padding='same', kernel_initializer=\"he_normal\")(branch_concat)\n",
    "\n",
    "    x = tf.keras.layers.Add(name='Inception_ResNet_Block_B'+str(i))([inputs, branch1x1_ln])\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    out = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    return out\n",
    "\n",
    "\"\"\"\n",
    "def Inception_ResNet_Module_C(inputs, filterB1_1, filterB2_1, filterB2_2, filterB2_3, filterB3_1, i):\n",
    "    # Inception ResNet Module C - Block i\n",
    "    branch1x1 = Conv_2D_Block(inputs, filterB1_1, (1, 1))\n",
    "\n",
    "    branch3x3 = Conv_2D_Block(inputs, filterB2_1, (1, 1))\n",
    "    branch3x3 = Conv_2D_Block(branch3x3, filterB2_2, (1, 3))\n",
    "    branch3x3 = Conv_2D_Block(branch3x3, filterB2_3, (3, 1))\n",
    "\n",
    "    branch_concat = tf.keras.layers.concatenate([branch1x1, branch3x3], axis=-1)\n",
    "    branch1x1_ln = tf.keras.layers.Conv2D(filterB3_1, (1, 1), activation='linear', strides=(1, 1), padding='same', kernel_initializer=\"he_normal\")(branch_concat)\n",
    "\n",
    "    x = tf.keras.layers.Add(name='Inception_ResNet_Block_C'+str(i))([inputs, branch1x1_ln])\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    out = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    return out\n",
    "\"\"\"\n",
    "\n",
    "def Reduction_Block_A(inputs, filterB1_1, filterB2_1, filterB2_2, filterB2_3):\n",
    "    # Reduction Block A\n",
    "    branch_pool = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(inputs)\n",
    "\n",
    "    branch3x3 = Conv_2D_Block(inputs, filterB1_1, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch3x3dbl = Conv_2D_Block(inputs, filterB2_1, (1, 1))\n",
    "    branch3x3dbl = Conv_2D_Block(branch3x3dbl, filterB2_2, (3, 3))\n",
    "    branch3x3dbl = Conv_2D_Block(branch3x3dbl, filterB2_3, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    x = tf.keras.layers.concatenate([branch_pool, branch3x3, branch3x3dbl], axis=-1, name='Reduction_Block_A')\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    out = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def Reduction_Block_B(inputs, filterB1_1, filterB1_2, filterB2_1, filterB2_2, filterB3_1, filterB3_2, filterB3_3):\n",
    "    # Reduction Block B\n",
    "    branch_pool = tf.keras.layers.MaxPooling2D(pool_size=(3, 3))(inputs)\n",
    "\n",
    "    branch3x3 = Conv_2D_Block(inputs, filterB1_1, (1, 1))\n",
    "    branch3x3 = Conv_2D_Block(branch3x3, filterB1_2, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch3x3_2 = Conv_2D_Block(inputs, filterB2_1, (1, 1))\n",
    "    branch3x3_2 = Conv_2D_Block(branch3x3_2, filterB2_2, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch3x3dbl = Conv_2D_Block(inputs, filterB3_1, (1, 1))\n",
    "    branch3x3dbl = Conv_2D_Block(branch3x3dbl, filterB3_2, (3, 3))\n",
    "    branch3x3dbl = Conv_2D_Block(branch3x3dbl, filterB3_3, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    x = tf.keras.layers.concatenate([branch_pool, branch3x3, branch3x3_2, branch3x3dbl], axis=-1)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    out = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "class Inception_ResNet:\n",
    "    def __init__(self, length, width, num_channel, num_filters, problem_type='Classification',\n",
    "                 output_nums=10, pooling='avg', dropout_rate=False, auxilliary_outputs=False):\n",
    "        # length: Input Image Length (x-dim)\n",
    "        # width: Input Image Width (y-dim) [Normally same as the x-dim i.e., Square shape]\n",
    "        # model_depth: Depth of the Model\n",
    "        # model_width: Width of the Model\n",
    "        # kernel_size: Kernel or Filter Size of the Input Convolutional Layer\n",
    "        # num_channel: Number of Channels of the Input Predictor Signals\n",
    "        # problem_type: Regression or Classification\n",
    "        # output_nums: Number of Output Classes in Classification mode and output features in Regression mode\n",
    "        # pooling: Choose either 'max' for MaxPooling or 'avg' for Averagepooling\n",
    "        # dropout_rate: If turned on, some layers will be dropped out randomly based on the selected proportion\n",
    "        # auxilliary_outputs: Two extra Auxullary outputs for the Inception models, acting like Deep Supervision\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        self.num_channel = num_channel\n",
    "        self.num_filters = num_filters\n",
    "        self.problem_type = problem_type\n",
    "        self.output_nums = output_nums\n",
    "        self.pooling = pooling\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.auxilliary_outputs = auxilliary_outputs\n",
    "\n",
    "    def MLP(self, x):\n",
    "        if self.pooling == 'avg':\n",
    "            x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        elif self.pooling == 'max':\n",
    "            x = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        if self.dropout_rate:\n",
    "            x = tf.keras.layers.Dropout(self.dropout_rate)(x)\n",
    "        outputs = tf.keras.layers.Dense(self.output_nums, activation='linear')(x)\n",
    "        if self.problem_type == 'Classification':\n",
    "            outputs = tf.keras.layers.Dense(self.output_nums, activation='softmax')(x)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def Inception_ResNet_v1(self):\n",
    "        inputs = tf.keras.Input((self.length, self.width, self.num_channel))  # The input tensor\n",
    "        # Stem\n",
    "        x = Conv_2D_Block(inputs, 32, 3)\n",
    "        x = Conv_2D_Block(x, 32, 3, padding='valid')\n",
    "      # x = Conv_2D_Block(x, 64, 3)\n",
    "        x = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "        x = Conv_2D_Block(x, 64, 1)\n",
    "        x = Conv_2D_Block(x, 128, 3)\n",
    "      # x = Conv_2D_Block(x, 128, 3, strides=(2, 2), padding='valid')\n",
    "        x = Conv_2D_Block(x, 128, 3)\n",
    "\n",
    "        # 5x Inception ResNet A Blocks - 35 x 35 x 256\n",
    "        for i in range(1):\n",
    "            x = Inception_ResNet_Module_A(x, 32, 32, 32, 32, 32, 32, 128, i)\n",
    "\n",
    "        aux_output_0 = []\n",
    "        if self.auxilliary_outputs:\n",
    "            # Auxilliary Output 0\n",
    "            aux_pool = tf.keras.layers.AveragePooling2D(pool_size=(5, 5), strides=(3, 3))(x)\n",
    "            aux_conv = Conv_2D_Block(aux_pool, 128, (1, 1))\n",
    "            aux_conv = Conv_2D_Block(aux_conv, 768, (5, 5), padding='valid')\n",
    "            aux_output_0 = self.MLP(aux_conv)\n",
    "\n",
    "        x = Reduction_Block_A(x, 192, 96, 96, 128)  # Reduction Block A: 17 x 17 x 768\n",
    "\n",
    "        # 10x Inception ResNet B Blocks - 17 x 17 x 768\n",
    "        for i in range(1):\n",
    "            x = Inception_ResNet_Module_B(x, 64, 64, 64, 64, 448, i)\n",
    "\n",
    "        aux_output_1 = []\n",
    "        if self.auxilliary_outputs:\n",
    "            # Auxilliary Output 1\n",
    "            aux_pool = tf.keras.layers.AveragePooling2D(pool_size=(5, 5), strides=(3, 3), padding='valid')(x)\n",
    "            aux_conv = Conv_2D_Block(aux_pool, 128, (1, 1))\n",
    "            aux_conv = Conv_2D_Block(aux_conv, 768, (5, 5), padding='valid')\n",
    "            aux_output_1 = self.MLP(aux_conv)\n",
    "\n",
    "        x = Reduction_Block_B(x, 128, 192, 128, 128, 128, 128, 128)  # Reduction Block B: 8 x 8 x 1280\n",
    "\n",
    "        \"\"\"\n",
    "        # 5x Inception ResNet C Blocks - 8 x 8 x 1280\n",
    "        for i in range(5):\n",
    "            x = Inception_ResNet_Module_C(x, 128, 192, 192, 192, 1792, i)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # Final Dense MLP Layer for the outputs\n",
    "        final_output = self.MLP(x)\n",
    "        # Create model.\n",
    "        model = tf.keras.Model(inputs, final_output, name='Inception_v4')\n",
    "        if self.auxilliary_outputs:\n",
    "            model = tf.keras.Model(inputs, outputs=[final_output, aux_output_0, aux_output_1], name='Inception_ResNet_v1')\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "model = Inception_ResNet(length=29, width=29, num_channel=1, num_filters=64, problem_type='Classification', output_nums=2, pooling='avg', dropout_rate=0.2).Inception_ResNet_v1()\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91ae2e38-3a63-41e6-aa87-15c9d7254702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6195/6195 - 96s - loss: 0.0140 - accuracy: 0.9948 - 96s/epoch - 15ms/step\n",
      "Epoch 2/10\n",
      "6195/6195 - 98s - loss: 0.0138 - accuracy: 0.9951 - 98s/epoch - 16ms/step\n",
      "Epoch 3/10\n",
      "6195/6195 - 98s - loss: 0.0137 - accuracy: 0.9949 - 98s/epoch - 16ms/step\n",
      "Epoch 4/10\n",
      "6195/6195 - 98s - loss: 0.0128 - accuracy: 0.9953 - 98s/epoch - 16ms/step\n",
      "Epoch 5/10\n",
      "6195/6195 - 97s - loss: 0.0127 - accuracy: 0.9955 - 97s/epoch - 16ms/step\n",
      "Epoch 6/10\n",
      "6195/6195 - 101s - loss: 0.0128 - accuracy: 0.9955 - 101s/epoch - 16ms/step\n",
      "Epoch 7/10\n",
      "6195/6195 - 98s - loss: 0.0121 - accuracy: 0.9957 - 98s/epoch - 16ms/step\n",
      "Epoch 8/10\n",
      "6195/6195 - 97s - loss: 0.0114 - accuracy: 0.9959 - 97s/epoch - 16ms/step\n",
      "Epoch 9/10\n",
      "6195/6195 - 97s - loss: 0.0116 - accuracy: 0.9959 - 97s/epoch - 16ms/step\n",
      "Epoch 10/10\n",
      "6195/6195 - 98s - loss: 0.0113 - accuracy: 0.9960 - 98s/epoch - 16ms/step\n"
     ]
    }
   ],
   "source": [
    "# Define a custom callback to log batch losses\n",
    "class BatchLossCSVLogger(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "\n",
    "# Create an instance of the custom callback\n",
    "batch_loss_logger = BatchLossCSVLogger()\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    batch_size=64,\n",
    "                    verbose=2,\n",
    "                    callbacks=[batch_loss_logger] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ac36e6b-c201-4cd6-bb54-d0aaa8fb4d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch validation losses saved to ./Models/22.DCNN_(VC)\\DCNN_Sliding_CAN_KIA_SOUL\\Replay_batch_losses.csv\n",
      "Epoch validation losses saved to ./Models/22.DCNN_(VC)\\DCNN_Sliding_CAN_KIA_SOUL\\Replay_epoch_val_losses.csv\n"
     ]
    }
   ],
   "source": [
    "# Write batch losses to a CSV file with a dynamic filename\n",
    "file_path = os.path.join(path, f'{attack}_batch_losses.csv')\n",
    "with open(file_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Batch', 'Loss'])\n",
    "    for i, loss in enumerate(batch_loss_logger.losses):\n",
    "        writer.writerow([i, loss])\n",
    "        \n",
    "print(f\"Batch validation losses saved to {file_path}\")\n",
    "\n",
    "# Save epoch validation losses to CSV\n",
    "csv_file_path = os.path.join(path, f'{attack}_epoch_val_losses.csv')\n",
    "with open(csv_file_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Epoch', 'Val_Loss'])\n",
    "    for i, val_loss in enumerate(batch_loss_logger.val_losses):\n",
    "        writer.writerow([i, val_loss])\n",
    "\n",
    "print(f\"Epoch validation losses saved to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20ddaa0-d2d2-4920-8794-7c2f4706a7a8",
   "metadata": {},
   "source": [
    "# Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2af9b739-ce07-435b-bdba-4f9409ef8a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5310/5310 [==============================] - 23s 4ms/step\n",
      "Confusion matrix saved to ./Models/22.DCNN_(VC)\\DCNN_Sliding_CAN_KIA_SOUL/Replay_confusion_matrix.csv\n",
      "Classification report saved to ./Models/22.DCNN_(VC)\\DCNN_Sliding_CAN_KIA_SOUL/Replay_classification_report.csv\n"
     ]
    }
   ],
   "source": [
    "# Perform prediction\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Select the class with the highest probability as the predicted value\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "# Convert the confusion matrix to a DataFrame and save it as a CSV file\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix)\n",
    "conf_matrix_file_name = f\"{path}/{attack}_confusion_matrix.csv\"\n",
    "conf_matrix_df.to_csv(conf_matrix_file_name, index=False)\n",
    "print(f\"Confusion matrix saved to {conf_matrix_file_name}\")\n",
    "\n",
    "# Generate a classification report\n",
    "class_report = classification_report(y_true, y_pred_classes, digits=4, output_dict=True)\n",
    "\n",
    "\n",
    "class_report_df = pd.DataFrame(class_report).transpose()\n",
    "class_report_file_name = f\"{path}/{attack}_classification_report.csv\"\n",
    "class_report_df.to_csv(class_report_file_name, index=True)\n",
    "print(f\"Classification report saved to {class_report_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0bc4f6b7-a920-4fd1-9ef3-c2a2800454ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119050</td>\n",
       "      <td>4317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4521</td>\n",
       "      <td>42005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1\n",
       "0  119050   4317\n",
       "1    4521  42005"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83ec4fa2-8c0d-431f-92e7-646066fcb8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 42005\n",
      "FP: 4317\n",
      "FN: 4521\n",
      "TN: 119050\n",
      "Accuracy: 0.9480\n",
      "Precision: 0.9068\n",
      "Recall: 0.9028\n",
      "F1 Score: 0.9048\n"
     ]
    }
   ],
   "source": [
    "# Extract True Positive, False Positive, False Negative, and True Negative from the confusion matrix\n",
    "# Assumption: Binary classification problem (0 and 1)\n",
    "TP = conf_matrix_df.iloc[1, 1]  # True Positive\n",
    "FP = conf_matrix_df.iloc[0, 1]  # False Positive\n",
    "FN = conf_matrix_df.iloc[1, 0]  # False Negative\n",
    "TN = conf_matrix_df.iloc[0, 0]  # True Negative\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "# Print the results\n",
    "print(f\"TP: {TP}\")\n",
    "print(f\"FP: {FP}\")\n",
    "print(f\"FN: {FN}\")\n",
    "print(f\"TN: {TN}\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c76140-3b60-434c-bf8c-94c79b1b8ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe9a41f-fe3c-44c0-ad69-c2e0002ad47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed7fe73-7853-4e51-a187-785a3eca59de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
